{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "haiku-basics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOsfFY4x7BGS34MXZh7RqbD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deterministic-algorithms-lab/Jax-Journey/blob/main/haiku_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOCnw0vnehKT"
      },
      "source": [
        "!pip install git+https://github.com/deepmind/dm-haiku"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vZsBj6BekmL"
      },
      "source": [
        "import haiku as hk\n",
        "import jax.numpy as jnp\n",
        "import jax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlOX_u66b9y1"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S0xBoBtjXoX"
      },
      "source": [
        "**Specialities :**\n",
        "\n",
        "* ```name``` argument in ```__init__``` . Module must call ```super().__init__()``` with its ```name``` .\n",
        "* ```__call__``` can take any arguments, return any. \n",
        "* Only single function(```__call__```) for both ```init_fn()``` and ```apply_fn()```. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs9VPPhiS9_V"
      },
      "source": [
        "class HaikuLSTMCell(hk.Module):\n",
        "    def __init__(self, in_dim, out_dim, name=None):\n",
        "        super().__init__(name=name or \"lstmcell\")\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "    \n",
        "    def __call__(self, inputs, h, c):\n",
        "        weights_ih = hk.get_parameter(\"weight_ih\", \n",
        "                                      (4*self.out_dim, self.in_dim),\n",
        "                                      init = hk.initializers.UniformScaling())\n",
        "        weights_hh = hk.get_parameter(\"weights_hh\",\n",
        "                                      (4*self.out_dim, self.out_dim),\n",
        "                                      init=hk.initializers.UniformScaling())\n",
        "        bias = hk.get_parameter(\"bias\",\n",
        "                                (4*self.out_dim,),\n",
        "                                init = hk.initializers.Constant(0.0))\n",
        "        \n",
        "        ifgo = weights_ih @ inputs + weights_hh @ h + bias\n",
        "        i, f, g, o = jnp.split(ifgo, indices_or_sections=4, axis=-1)\n",
        "        \n",
        "        i = jax.nn.sigmoid(i)\n",
        "        f = jax.nn.sigmoid(f)\n",
        "        g = jnp.tanh(g)\n",
        "        o = jax.nn.sigmoid(o)\n",
        "\n",
        "        new_c = f*c + i * g\n",
        "        new_h = o*jnp.tanh(new_c)\n",
        "        \n",
        "        return (new_h, new_c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8rKZnrAm4IB"
      },
      "source": [
        "The following code is even more like PyTorch :\n",
        "* You can define all submodules and parameters inside ```__init__()```. All things that happen inside the function that is sent into ```hk.transform()``` will be well traced, and are valid. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1zykpR3efQa"
      },
      "source": [
        "class HaikuLSTMLM(hk.Module):\n",
        "    def __init__(self, vocab_size, dim, name=None):\n",
        "        super().__init__(name=name or \"lstmlm\")\n",
        "        _c0 = hk.get_parameter(name=\"c_0\",\n",
        "                               shape = (dim,),\n",
        "                              \n",
        "                               init = hk.initializers.TruncatedNormal(stddev=0.1))\n",
        "        self.hc_0 = (jnp.tanh(_c0), _c0)\n",
        "        self.embeddings = hk.Embed(vocab_size, dim)\n",
        "        self.cell = HaikuLSTMCell(dim, dim)\n",
        "    \n",
        "    def forward(self, seq, hc):\n",
        "        loss = 0\n",
        "        for idx in seq:\n",
        "            loss -= jax.nn.log_softmax(self.embeddings.embeddings@hc[0])[idx]\n",
        "            hc = self.cell(self.embeddings(idx), *hc)\n",
        "        return loss, hc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkHZw77241zx"
      },
      "source": [
        "* It doesn't matter to ```hk.transform()``` where the submodules are defined, as long as they are defined within the function that is being transformed so that they can be purified. So both the above and below definition are valid and equivalent. \n",
        "\n",
        "* The second way allows you to make model sizes dependent on inputs received in ```forward()```\n",
        "\n",
        "* The ```forward()``` function need not be named as it is , and can have any other name. Some poeple use ```__call__```, instead. We are able to use syntax like in line 16 below, (```hk.Embed(.. , ..)(idx)```) because the processing done ```hk.Embed``` is defined in its ```__call__```, rather than forward. Had it been defined in ```forward()```, we'd have to call ```hk.Embed(.. , ..).forward(idx)``` instead. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIFcJvXD5hNN"
      },
      "source": [
        "class HaikuLSTMLM(hk.Module):\n",
        "    def __init__(self, vocab_size, dim, name=None):\n",
        "        super().__init__(name=name or \"lstmlm\")\n",
        "        _c0 = hk.get_parameter(name=\"c_0\",\n",
        "                               shape = (dim,),\n",
        "                               init = hk.initializers.TruncatedNormal(stddev=0.1))\n",
        "        self.hc_0 = (jnp.tanh(_c0), _c0)\n",
        "        self.vocab_size=vocab_size\n",
        "        self.dim = dim\n",
        "        self.cell = HaikuLSTMCell(dim, dim)\n",
        "    \n",
        "    def forward(self, seq, hc):\n",
        "        loss = 0\n",
        "        for idx in seq:\n",
        "            loss -= jax.nn.log_softmax(hk.Embed(self.vocab_size, self.dim).embeddings@hc[0])[idx]\n",
        "            hc = self.cell(hk.Embed(self.vocab_size, self.dim)(idx), *hc)\n",
        "        return loss, hc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2KjbdiWqV_7"
      },
      "source": [
        "def impure_forward_fn(vocab_size, dim, seq, hc=None):\n",
        "    lm = HaikuLSTMLM(vocab_size, dim)\n",
        "    return lm.forward(seq, hc if hc else lm.hc_0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A48Q-7UrUiw"
      },
      "source": [
        "init_fn, nojit_pure_forward_fn = hk.transform(impure_forward_fn)\n",
        "pure_forward_fn = jax.jit(nojit_pure_forward_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-TPkGpxvdxA"
      },
      "source": [
        "* ```init_fn()``` takes in two types of arguments. First is the random key and second are the inputs to be sent to the function that was transformed. It returns the nested params.\n",
        "\n",
        "* ```nojit_pure_forward_function``` takes in three types of arguments. First is the ```params``` returned by ```init_fn()``` and second is the ```rng``` key and third are the arguments to the function that was transformed. Same ```rng``` key will give same result on same inputs. It returns the same things that are returned by ```impure_forward_fn()``` . "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOt9BFBju9J-"
      },
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "params = init_fn(rng, vocab_size = 20, dim = 10, seq=jnp.array([0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHVDpHkyw4-g"
      },
      "source": [
        "print(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku-lknH6xFhu"
      },
      "source": [
        "loss, hc = nojit_pure_forward_fn(params, rng, vocab_size = 20, dim=10, seq=jnp.array([0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyQly5IryrIe",
        "outputId": "e46cc3c0-9183-47c9-a4e1-8b36bc40b9b7"
      },
      "source": [
        "print(loss, hc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.9562287 (DeviceArray([ 0.19030678, -0.04981524, -0.1435111 ,  0.14797553,\n",
            "              0.01645921, -0.01669403,  0.11530687, -0.10629394,\n",
            "             -0.02137115,  0.07460269], dtype=float32), DeviceArray([ 0.37595972, -0.08241095, -0.2591579 ,  0.3729893 ,\n",
            "              0.0248227 , -0.03331303,  0.19235653, -0.24751279,\n",
            "             -0.04453837,  0.15290585], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}